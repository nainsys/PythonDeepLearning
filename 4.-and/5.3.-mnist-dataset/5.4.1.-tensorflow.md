# 5.4.1. 	기본 TensorFlow 메커니즘

TensorFlow 런타임 환경의 기본 요소 인 graphs, sessions에 대해 설명합니다.

**1\)    Graphs**

텐서플로우를 실행하려면 다음의 과정을 따라야 합니다.

TensorFlow 프로그램은 크게 두 가지 단계로 구성되어 있습니다. 구성 단계에서는 graph를 조립하고, 실행 단계에서는 session을 이용해 graph의 연산을 실행합니다.

Tensorflow에 대한 가장 큰 아이디어는 모든 수치 계산이 graph로 표현된다는 것입니다. 즉, Tensorflow 프로그램의 기본 골격은 graph입니다. graph는 모델의 작업을 나타내는 노드 배열입니다.

먼저 노드와 연산이 무엇을 의미하는지 봅시다. 그것을 설명하는 가장 좋은 방법은 간단한 예를 보는 것입니다. 함수 “f \(x, y\) = x ^ 2y + y + 2”의 코드를 작성하려고 가정 해 봅시다. TensorFlow의 graph는 다음과 같습니다.

그래프는 위의 그림처럼 Edge에 의해 서로 연결되어있는 일련의 Node들로 구성됩니다. graph의 각 노드는 op \(operation\)라고합니다. 따라서 우리는 “텐서\(변수, 상수\)” 또는 “텐서에 대한 연산\(수학 연산\)”을 위해 각 연산에 대해 하나의 노드를 갖습니다. 각 노드는 0개 이상의 텐서를 입력으로 사용하고 0개 이상의 텐서를 출력으로 생성합니다.

operation  "Add" 코드는 다음과 같습니다.

import tensorflow as tf

a = 2

b = 3

c = tf.add\(a, b, name='Add'\)

print\(c\)

이 코드의 결과는 다음과 같습니다.

Tensor\("Add:0", shape=\(\), dtype=int32\)

생성된 그래프와 변수들은

이 코드는 두 개의 입력 노드 \(a = 2 및 b = 3\)와 하나의 출력 노드\(Add\)를 만듭니다. 변수 c \(즉 덧셈 연산의 출력 Tensor\)를 출력하면 Tensor 정보가 출력됩니다. 그 이름 \(Add\), shape\(\)는 스칼라를 의미하고 type \(32-bit integer\). 그러나 결과를 출력하지는 않습니다 \(2 + 3 = 5\). 왜 그럴까요?

TensorFlow 프로그램은 두 가지 단계로 구성되어 있다고 이야기했습니다. 첫 번째 단계는 graph를 만들고 노드를 평가하는 것이고 두번째 단계로 session에서 계산 graph를 실행해야합니다. 간단히 말하면, 작성된 코드는 예상되는 Tensors의 크기와 실행되는 작업만 결정하는 graph를 생성한 것입니다. 그러나 Tensor에 숫자 값을 지정하지 않습니다. 즉, TensorFlow는 session에서 지정하지 않는 한 graph를 실행하지 않습니다. 따라서 이러한 값을 할당하고 graph를 통해 흐름\(Flow\)을 만들려면 session을 만들고 실행해야합니다.

TensorFlow graph는 Python의 함수 정의와 같습니다. 함수 정의에 실행 결과가없는 것처럼 계산을 수행하지 않습니다.

**2\)    Session**

빌드 준비가 끝나고 모든 op들도 생성되면 graph를 실행하기 위해 session을 생성해야 합니다. 무엇이든 계산하려면 session에서 graph를 실행해야 합니다. 기술적으로 session은 CPU 또는 GPU와 같은 하드웨어에 graph 작업을 배치하고 이를 실행하는 메소드를 제공합니다. 예제에서 graph를 실행하고 c의 값을 얻으려면 다음 코드가 session을 만들고 'c'를 실행하여 graph를 실행합니다.

sess = tf.Session\(\)

print\(sess.run\(c\)\)

sess.close\(\)

먼저 실습한 코드 하단에 위의 코드를 추가해야 우리가 원하는 “5”라는 결과를 얻을 수 있습니다.

이 코드는 session 객체\(sess에 할당됨\)를 생성한 다음 \(두 번째 행\) run 메소드를 호출하여 c를 평가할 수있는 계산 graph를 실행합니다. 이것은 c의 값을 얻는데 필요한 graph만 실행한다는 것을 의미합니다. session이 끝나면 session을 닫는 것을 잊지 마십시오. 위의 코드에서 마지막 줄은 session을 닫는 것입니다.

다음 코드는 동일한 작업을 수행하며 일반적으로 많이 사용됩니다. 유일한 차이점은 자동으로 닫히기 때문에 마지막에 세션을 닫을 필요가 없다는 것입니다.

**with** tf.Session\(\) **as** sess:

    print\(sess.run\(c\)\)

명확하게 설명하기 위해 "Python-name"과 "TensorFlow-name" 으로 분리해서 설명해 보겟습니다.

이 코드에서는 a, b 및 c의 "Python-name"으로 3 개의 변수를 생성했습니다. 여기서 a와 b는 파이썬 변수이므로 "TensorFlow-name"이 없습니다. c는 "TensorFlow-name"으로 Add가 있는 Tensor입니다. 이상적인 Tensorflow 경우, tf.add \(\)는 "TensorFlow-name"이 정의된 두 개의 Tensors를 입력합니다 \(이 이름은 Python-name과 별개입니다\). 예를 들어,  c = tf.add \(a, b, name = 'Add'\) 를 쓰면 실제로 파이썬 이름이 c이고 TensorFlow 이름이 Add 인 변수 \(또는 Tensor\)가 생성됩니다.

위의 코드에서 Python Name \(a,b\)만 있는 두 개의 Python 변수 \(a = 2 및 b = 3\)를 전달했지만 TensorFlow Name은 없습니다. TensorFlow는 그래프를 시각화하기 위해 TensorFlow Name을 사용합니다. a와 b에는 TensorFlow Name이 없으므로 기본 이름인 x와 y를 사용합니다.

조금더 복잡한 예제를 살펴봅시다.

import tensorflow as tf

x = 2

y = 3

add\_op = tf.add\(x, y, name='Add'\)

mul\_op = tf.multiply\(x, y, name='Multiply'\)

pow\_op = tf.pow\(add\_op, mul\_op, name='Power'\)

useless\_op = tf.multiply\(x, add\_op, name='Useless'\)

with tf.Session\(\) as sess:

    pow\_out, useless\_out = sess.run\(\[pow\_op, useless\_op\]\)

위의 예제에서 생성되는 그래프와 정의되는 변수들은 다음과 같습니다.

이 그래프가 주어지면 pow\_op 연산을 가져오면 먼저 add\_op와 mul\_op을 실행하여 출력 텐서를 얻은 다음 pow\_op을 실행하여 필요한 출력 값을 계산합니다. 즉, pow\_op 연산의 실행에 텐서가 사용되지 않기 때문에 useless\_op은 실행되지 않습니다.

이것은 그래프를 정의하고 그것에 세션을 실행하는 장점 중 하나입니다. 그래프의 필수 연산 만 실행하고 나머지는 건너 뜁니다. 이것은 수백, 수천 개의 작업으로 거대한 네트워크를 처리할 때  많은 시간을 절약합니다.

위의 코드에서 정의 된 세션에서 동시에 두 개의 텐서 값 \(pow\_op 및 useless\_op의 출력 텐서\)을 가져옵니다. 이것은 전체 그래프를 실행하여 필요한 출력 텐서를 얻습니다.

